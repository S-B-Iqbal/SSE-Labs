{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install ucimlrepo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from pathlib import Path\n",
    "from ucimlrepo import fetch_ucirepo\n",
    "\n",
    "from scipy.stats import zscore\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.pipeline import make_pipeline, Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "# pd.options.plotting.backend = \"plotly\"\n",
    "\n",
    "import plotly.express as px\n",
    "# import plotly.graph_objects as go\n",
    "# import plotly.figure_factory as ff\n",
    "\n",
    "from helper import (generate_confusion_matrix, generate_classification_report, generate_statistical_summary,\n",
    "                    generate_logistic_model_weights, generate_std_model_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_RS, MODEL_RS = 100,100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ucimlrepo import fetch_ucirepo\n",
    "# fetch dataset \n",
    "data = fetch_ucirepo(id=544) \n",
    "  \n",
    "# data (as pandas dataframes) \n",
    "X = data.data.features \n",
    "y = data.data.targets \n",
    "\n",
    "\n",
    "# x_std = zscore(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([X,y], axis=1, join=\"inner\")\n",
    "\n",
    "def binarize_y(target:str):\n",
    "    \"\"\"\"\"\"\n",
    "    if target in [\"Insufficient_Weight\", \"Normal_Weight\"]:\n",
    "        return \"low risk\"\n",
    "    else:\n",
    "        return \"high risk\"\n",
    "    \n",
    "df[\"target\"] = df.NObeyesdad.apply(binarize_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q-1\n",
    "\n",
    "- Make a general statement abot **TP**, **TN**, **FP**, and **FN** in the context of this problem. (Hint: Think in terms of normal and overweight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_target(df,target_col):\n",
    "    fig = px.histogram(df,x=f\"{target_col}\", color=f\"{target_col}\", color_discrete_sequence=[\"grey\", \"cyan\"])\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_target(df=df, target_col=\"target\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q-2\n",
    "\n",
    "- Assume that the ML model youre building is deployed in a country which has an obesity crisis but diagnosis is inexpansive. What Metric would you choose? \n",
    "- Now, assume that another ML model needs to be deployed in a country with obesity crisis but the diagnosis is very expansive. What Metric would you use in the latter case? Provide motivation.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q-3\n",
    "There are two Logistic Regression models built based on this dataset: One model is trained using standardized data, and another without using the standardized data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing\n",
    "features = ['Gender', 'Age', 'Height', 'Weight', 'family_history_with_overweight',\n",
    "       'FAVC', 'FCVC', 'NCP', 'CAEC', 'SMOKE', 'CH2O', 'SCC', 'FAF', 'TUE',\n",
    "       'CALC', 'MTRANS']\n",
    "target = [\"target\"]\n",
    "\n",
    "def deobjectify_df(X:pd.DataFrame):\n",
    "    \"\"\"\"\"\"\n",
    "\n",
    "    # List to store Categorical Columns\n",
    "    cat_cols = list(X.columns[X.dtypes == 'object'])\n",
    "    print(\"Categorical Columns: \",cat_cols)\n",
    "\n",
    "    # List to store Numerical Columns\n",
    "    num_cols = list(X.columns[X.dtypes != 'object'])\n",
    "    print(\"\\nNumerical Columns:\" ,num_cols)\n",
    "\n",
    "    ## One-Hot Encoding Categorical Columns\n",
    "    x_dummy =  pd.get_dummies(X[cat_cols], drop_first=True)\n",
    "\n",
    "    ## Joining New dummified and Numerical columns\n",
    "    x_new = pd.concat([x_dummy, X[num_cols]], axis=1, join='inner')\n",
    "    return x_new\n",
    "\n",
    "x_new = deobjectify_df(X=df[features])\n",
    "\n",
    "def get_train_val_test(X,y):\n",
    "    x_train, x_int, y_train, y_int = train_test_split(X,y, random_state=DATA_RS,test_size=0.5, stratify=y)\n",
    "    x_val, x_test, y_val, y_test = train_test_split(x_int,y_int, random_state=DATA_RS,test_size=0.5, stratify=y_int)\n",
    "    return x_train,x_val,x_test, y_train,y_val,y_test\n",
    "\n",
    "x_train,x_val,x_test, y_train,y_val,y_test = get_train_val_test(X=x_new,y=df[target])\n",
    "\n",
    "lr = LogisticRegression(penalty=\"none\", random_state=MODEL_RS, max_iter=2500)\n",
    "lr_std= LogisticRegression(penalty=\"none\", random_state=MODEL_RS, max_iter=1000)\n",
    "std_steps = [(\"Scaling\", StandardScaler()), (\"Modeling\", lr_std)]\n",
    "std_pipeline = Pipeline(steps=std_steps)\n",
    "\n",
    "\n",
    "lr.fit(x_train, np.ravel(y_train))\n",
    "\n",
    "std_pipeline.fit(x_train, np.ravel(y_train))\n",
    "\n",
    "def get_model_pred(model, x_pred):\n",
    "    y_hat = model.predict(x_pred)\n",
    "    return y_hat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1\n",
    "- Report **_Prediction_** error for both the models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_classification_report(y_true=y_val, y_pred=get_model_pred(lr,x_val), target_names=lr.classes_.tolist(), split=\"Logistic Model: Validation\")\n",
    "generate_classification_report(y_true=y_val, y_pred=get_model_pred(std_pipeline,x_val), target_names=std_pipeline.classes_.tolist(), split=\"Regularized Model: Validation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_confusion_matrix(y_true=y_test, y_pred=get_model_pred(lr,x_test), labels=lr.classes_.tolist(), title=\"-->Data: Non-Standardized, Set: Test\")\n",
    "generate_confusion_matrix(y_true=y_test, y_pred=get_model_pred(std_pipeline,x_test), labels=std_pipeline.classes_.tolist(), title=\"-->Data: Standardized, Set: Test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2\n",
    "- Visually analyze the weight coefficients of both the mdoels. Provide your interpretation for the 3 most impactful features.\n",
    "- The weights differ quite significantly in both the models. Can you suggest the reason for the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_logistic_model_weights(lr,model_name=\"Logistic Model\")\n",
    "generate_std_model_weights(std_pipeline,model_name=\"Standardized Model\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mirandalabs",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
